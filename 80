import psycopg2
from faker import Faker
import time

# Connect to PostgreSQL
conn = psycopg2.connect(
    dbname="postgres",
    user="postgres",
    password="postgres",
    host="localhost",
    port="5432"
)

# Create a cursor
cur = conn.cursor()

# Measure the start time
start_time = time.time()

# Create the table with 80 columns
create_table_query = """
    CREATE TABLE example_table (
        id SERIAL PRIMARY KEY,
        """ + ", ".join([f"column_{i} TEXT" for i in range(1, 81)]) + """
    )
"""
cur.execute(create_table_query)

# Generate large data
fake = Faker()
data_size = 15000  # Number of rows to insert
chunk_size = 1000   # Adjust as per your system resources

while data_size > 0:
    chunk_data = [(fake.text(),) * 80 for _ in range(min(chunk_size, data_size))]
    cur.executemany("INSERT INTO example_table (" + ", ".join([f"column_{i}" for i in range(1, 81)]) + ") VALUES (" + ", ".join(["%s"] * 80) + ")", chunk_data)
    data_size -= chunk_size

# Measure the time after data insertion
data_insertion_time = time.time() - start_time

# Create indexes on all columns
for i in range(1, 81):
    cur.execute(f"CREATE INDEX idx_column_{i} ON example_table (column_{i})")

# Commit the transaction
conn.commit()

# Measure the end time
end_time = time.time()

# Calculate the total elapsed time
total_elapsed_time = end_time - start_time

# Close the cursor and connection
cur.close()
conn.close()

# Print the time taken for data insertion and index creation
print(f"Data insertion completed in {data_insertion_time:.2f} seconds")
print(f"Index creation completed in {total_elapsed_time - data_insertion_time:.2f} seconds")
print(f"Total elapsed time: {total_elapsed_time:.2f} seconds")
